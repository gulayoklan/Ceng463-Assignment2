{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulayoklan/Ceng463-Assignment2/blob/main/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r0vqzowCsa9"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqivf6zFWqF7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import gc\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import transformers\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup, AutoTokenizer\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "Cl_8IxeKLUgc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBPyfqhxW6lb"
      },
      "outputs": [],
      "source": [
        "file_path = \"power-it-train.tsv\"\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "# Keep only the necessary columns (text and label) and drop rows with missing values\n",
        "df = df[['text_en', 'text' ,'label']].dropna()\n",
        "\n",
        "# Ensure the label column is binary and of type integer\n",
        "df['label'] = df['label'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Stratified split into train, validation, and test sets\n",
        "train, temp = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
        "val, test = train_test_split(temp, test_size=0.5, stratify=temp['label'], random_state=42)\n",
        "\n",
        "test.head()\n",
        "print(df['label'].unique())\n",
        "print(\"Train label counts:\\n\", train['label'].value_counts())\n",
        "print(\"Val   label counts:\\n\", val['label'].value_counts())\n",
        "print(\"Test  label counts:\\n\", test['label'].value_counts())"
      ],
      "metadata": {
        "id": "FBcz069u4T3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#oversampling to resolve the class imbalance problem\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate majority and minority classes\n",
        "train_majority = train[train.label == 0]\n",
        "train_minority = train[train.label == 1]\n",
        "\n",
        "print(\"Before oversampling:\")\n",
        "print(train['label'].value_counts())\n",
        "\n",
        "# Upsample minority class\n",
        "train_minority_upsampled = resample(\n",
        "    train_minority,\n",
        "    replace=True,             # sample with replacement\n",
        "    n_samples=len(train_majority),    # to match majority class\n",
        "    random_state=42           # reproducible results\n",
        ")\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "train_oversampled = pd.concat([train_majority, train_minority_upsampled])\n",
        "\n",
        "print(\"After oversampling:\")\n",
        "print(train_oversampled['label'].value_counts())\n",
        "# Shuffle the oversampled training data\n",
        "train = train_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "W8iSaMvl4T_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHHIv4juXyo2"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model =BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvyhYYFPXOc1"
      },
      "outputs": [],
      "source": [
        "def preprocess(data,tokenizer):\n",
        "  input_ids=[]\n",
        "  attention_masks=[]\n",
        "  sentences=data.text.values\n",
        "  labels=data.label.values\n",
        "  for sentence in sentences:\n",
        "    encoded_dict=tokenizer.encode_plus(sentence,\n",
        "                                            add_special_tokens=True,\n",
        "                                            max_length=512,\n",
        "                                            padding=\"max_length\",\n",
        "                                            truncation=True,\n",
        "                                            return_attention_mask=True,\n",
        "                                            return_tensors='pt')\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "  return TensorDataset(input_ids,attention_masks,labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcshIvMGZAT2"
      },
      "outputs": [],
      "source": [
        "train_data=preprocess(train,tokenizer)\n",
        "val_data=preprocess(val,tokenizer)\n",
        "test_data=preprocess(test,tokenizer)\n",
        "\n",
        "train_dataloader=DataLoader(train_data,batch_size=8)\n",
        "validation_dataloader=DataLoader(val_data,batch_size=8)\n",
        "test_dataloader=DataLoader(test_data,batch_size=8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w8eEmTRZaWJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "8K7FRu0kLawX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yqTqI4fZubz"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxPNUHBEZ90b"
      },
      "outputs": [],
      "source": [
        "\n",
        "epochs = 6\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPfM_9KAaUAJ"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2k1-9QIaUpH"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5EqU028aYdq",
        "outputId": "3859e363-0580-465e-8f41-46a5dbd8183f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epoch took: 0:14:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n"
          ]
        }
      ],
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "best_eval_accuracy = 0\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    #Training\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(b_input_ids,\n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=b_input_mask,\n",
        "                             labels=b_labels)\n",
        "        loss = output.loss\n",
        "        total_train_loss += loss.item()\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "    # Validation\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "            output= model(b_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "        loss = output.loss\n",
        "        total_eval_loss += loss.item()\n",
        "        logits = output.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    if avg_val_accuracy > best_eval_accuracy:\n",
        "        torch.save(model, 'bert_model_power')\n",
        "        best_eval_accuracy = avg_val_accuracy\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waMLLMplay_q",
        "outputId": "76733256-c322-4be3-a6c0-e476266c8385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-e374b6cafc0c>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('bert_model_power')\n"
          ]
        }
      ],
      "source": [
        "model = torch.load('bert_model_power')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zZpBGYxaziy",
        "outputId": "b7fa37a0-b34a-4427-eeb5-9081f50f41f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.90      0.83       491\n",
            "           1       0.76      0.55      0.64       294\n",
            "\n",
            "    accuracy                           0.77       785\n",
            "   macro avg       0.76      0.72      0.73       785\n",
            "weighted avg       0.77      0.77      0.76       785\n",
            "\n",
            "(array([0, 1]), array([572, 213]))\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "for batch in test_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        with torch.no_grad():\n",
        "            output= model(b_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=b_input_mask)\n",
        "            logits = output.logits\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "\n",
        "            predictions.extend(list(pred_flat))\n",
        "\n",
        "labels=[label for label in test.label.values]\n",
        "print(classification_report(labels,predictions))\n",
        "print(np.unique(predictions, return_counts=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOHVq8pPeTy5Ng4lrN0oGHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}